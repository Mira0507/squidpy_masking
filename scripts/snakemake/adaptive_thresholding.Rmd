---
title: "Adaptive thresholding"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import dask.array as da
import matplotlib.pyplot as plt
import squidpy as sq
from matplotlib.colors import ListedColormap
from skimage.morphology import binary_erosion
from skimage.filters import threshold_local
import xarray as xr
import os
import ast
```

```{python config}
# ------------------------------------------------------------------------------
# This chunk configures user-specified variables
# ------------------------------------------------------------------------------
stop()
# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Paths to input and output obj
input_obj = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']

# Set parameters for adaptive thresholding
# - block_size: neighborhood size, ~5â€“15% of the image dimension, odd integer.
# - offset: a constant added to (or subtracted from) the computed threshold (set to 0 by default)
#           higher offset results in more stringent thresholding
block_size = params['block_size']
offset = params['offset']


# Path to output directory
outdir = params['outdir']
```

# Loading input image

```{python loading_input}

# ------------------------------------------------------------------------------
# This chunk imports input image saved as zarr in the previous step
# ------------------------------------------------------------------------------

# Load the Zarr store into an ImageContainer
# Set lazy=True to enable Dask-backed lazy loading, which is memory-efficient for large images.
# You can also specify chunks for Dask if needed.
img = sq.im.ImageContainer.load(input_obj, lazy=True, chunks='auto')

print(f"The following file has been loaded: {input_obj}")
print(img)
```


# Adaptive thresholding {.tabset}

We rerun thresholding to address the uneven results produced by the Otsu method.
[Adaptive thresholding (aka local thresholding)](https://scikit-image.org/docs/0.25.x/auto_examples/applications/plot_thresholding_guide.html#local-thresholding) 
is applied to achieve more uniform thresholding results across the pixels,
using the `threshold_local` function from the `scikit-image` package. Threshold values are
calculated as the weighted mean of the local neighborhood minus an offset value.

```{python prep_local_thresholding}

# --------------------------------------------------------------------------------
# This chunk prepares a function to run adaptive thresholding
# --------------------------------------------------------------------------------

def adaptive_thresh(block_size, offset, channel, erosion=True):
    # Extract smoothened array per channel
    smth = img[lyr_smth].values[:, :, 0, channel]
    
    # Run local thresholding
    local_thresh = threshold_local(smth, block_size=block_size, offset=offset)
    mask = smth > local_thresh

    prefix = "adaptive"

    # Run erosion of specified
    if erosion:
        mask = binary_erosion(mask)
        prefix = f"{prefix}_erosion"

    # Specify file path prefix
    prefix = f"{prefix}_channel_{channel}"

    # Add the binarized image to the `img` obj
    img.add_img(mask.astype(np.uint8), layer=prefix)
    
    # print and save
    plt.imshow(mask, cmap=ListedColormap(['black', 'white']))
    plt.xticks([])
    plt.yticks([])
    plt.savefig(f"{outdir}/{prefix}.png", dpi=1000)
    plt.show()

```


## Before erosion {.tabset}

### DAPI

```{python adaptive_dapi, fig.height=12, fig.width=12}
i = 0
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=False)
outfile = f"{outdir}/adaptive_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### IBA1

```{python adaptive_iba, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=False)
outfile = f"{outdir}/adaptive_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### TDP43

```{python adaptive_tdp, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=False)
outfile = f"{outdir}/adaptive_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### MAP2

```{python adaptive_map, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=False)
outfile = f"{outdir}/adaptive_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### ALDH1L1

```{python adaptive_aldh, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=False)
outfile = f"{outdir}/adaptive_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

## After erosion {.tabset}

### DAPI

```{python erosion_dapi, fig.height=12, fig.width=12}
i = 0
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=True)
outfile = f"{outdir}/adaptive_erosion_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### IBA1

```{python erosion_iba, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=True)
outfile = f"{outdir}/adaptive_erosion_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### TDP43

```{python erosion_tdp, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=True)
outfile = f"{outdir}/adaptive_erosion_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### MAP2

```{python erosion_map, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=True)
outfile = f"{outdir}/adaptive_erosion_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

### ALDH1L1

```{python erosion_aldh, fig.height=12, fig.width=12}
i += 1
adaptive_thresh(block_size=block_size, offset=offset, channel=i, erosion=True)
outfile = f"{outdir}/adaptive_erosion_channel_{i}.png"
```

- Download: [`r py$outfile`](`r py$outfile`)

## Before & after erosion {.tabset}

`ImageContainer` updated:

```{r obj_after_adaptive_thresh}
py$img
```

Color code:

- BEFORE erosion: *Lime*
- AFTER erosion: *Salmon*

```{python prep_comparing_erosion}

# --------------------------------------------------------------------------------
# This chunk prepares to explore the effect of erosion by merging images before
# and after erosion 
# --------------------------------------------------------------------------------

# Create a function that merges IF signals before and after erosion
def compare_erosion(image, channel):
    # Filter layers before and after erosion for all channels
    lyr_compared = [l for l in list(image) if "adaptive" in l]
    lyr_compared = [l for l in lyr_compared if str(channel) in l]

    arr_dic = {}
    for l in lyr_compared:
        if "erosion" in l:
            arr_dic[l] = {"array": np.squeeze(img[l].values), "color": "Salmon"}
        else:
            arr_dic[l] = {"array": np.squeeze(img[l].values), "color": "Lime"}

    for arr in arr_dic.values():
        plt.imshow(arr['array'],
                   cmap=ListedColormap([(1, 1, 1, 0), arr['color']]), 
                   alpha=0.5)
    plt.yticks([])
    plt.xticks([])
    plt.show()

```

### DAPI

```{python compare_dapi, fig.height=12, fig.width=12}
i = 0
compare_erosion(image=img, channel=i)
```

### IBA1

```{python compare_iba, fig.height=12, fig.width=12}
i += 1
compare_erosion(image=img, channel=i)
```

### TDP43

```{python compare_tdp, fig.height=12, fig.width=12}
i += 1
compare_erosion(image=img, channel=i)
```

### MAP2

```{python compare_map, fig.height=12, fig.width=12}
i += 1
compare_erosion(image=img, channel=i)
```

### ALDH1L1

```{python compare_aldh, fig.height=12, fig.width=12}
i += 1
compare_erosion(image=img, channel=i)
```



# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```


```{r session_info, collapse=FALSE}
sessionInfo()
```
