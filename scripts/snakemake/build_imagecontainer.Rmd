---
title: "Segmentation using squidpy"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
```

```{python ppackages}
import numpy as np
import matplotlib.pyplot as plt
import squidpy as sq
from tifffile import imread
from matplotlib.colors import ListedColormap
from skimage.filters import threshold_local
from skimage.morphology import binary_erosion
from skimage.exposure import equalize_adapthist
import xarray as xr
import napari
import os
```

```{r configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Specify file paths to input and output files
outdir <- params[['outdir']]
input_image <- params[['input_image']]
output_obj <- params[['output_obj']]

# Specify the name of input image layer to be processed
lyr <- params[['lyr']]

# Specify signal values to be tested for Gaussian smoothing
# Sigma represents the variance for normal distribution
gaussian_sigma <- params[['gaussian_sigma']]

# Specify whether to equalize contrasts
equalize <- params[['equalize']]

# Specify whether input images will be cropped
crop_images <- params[['crop_images']]

# Specify coordinates to crop images
crop_coord <- params[['crop_coord']]
```

```{python config}

# ------------------------------------------------------------------------------
# This chunk converts variables from r to python
# ------------------------------------------------------------------------------

outdir = r.outdir
input_image = r.input_image
output_obj = r.output_obj
lyr = r.lyr
gaussian_sigma = int(r.gaussian_sigma)
equalize = r.equalize
crop_images = r.crop_images
crop_coord = r.crop_coord
```

# Loading input images {.tabset}

We use `tif` image files converted from `vsi`. The following channels correspond to individual IFs.

- **Channel 0**: DAPI
- **Channel 1**: IBA1
- **Channel 2**: TDP43
- **Channel 3**: MAP2
- **Channel 4**: ALDH1L1

The following image object loaded:

```{python load_image}

# ------------------------------------------------------------------------------
# This chunk is used to load input image files
# ------------------------------------------------------------------------------

# Read image as numpy array
img_array = imread(input_image)

# Initialize ImageContainer
img = sq.im.ImageContainer(img_array, layer=lyr)

print("ImageContainer obj created using input image:", img)

# Crop input images if specified
if crop_images == "Y":
    print("Image cropped. Refer to the following dimension:", crop_coord)
    img = img.crop_corner(x=crop_coord['width'],
                          y=crop_coord['height'],
                          size=crop_coord['size'],
                          scale=crop_coord['scale'])
    print("ImageContainer obj updated:", img)

# Run adaptive equalization
eq_img = equalize_adapthist(img[lyr])
# Convert to xarray
eq_img = xr.DataArray(eq_img)
# Replace the input array with equalized array
eq_lyr = f"{lyr}_eq"
img[eq_layer] = eq_img
print("Adaptive equalization applied to the input image!")
```

`ImageContainer` obj created using input image:

```{python print_status}
print(input_image)
print(img)
```

Two layers generated:

- `r py$lyr`: raw input 
- `r py$eq_lyr`: contrast-enhanced input

Contrast enhancement is conducted using the `skimage.exposure.equalize_adapthist`
function with default parameter settings.

## Before equalization {.tabset}


### Channel 0

```{python individual_images_c0, fig.height=12, fig.width=12}
active_lyr = lyr
prefix = "input_before_equalization_channel_"

i = 0
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```
- Download: [`r py$save_path`](`r py$save_path`)

### Channel 1

```{python individual_images_c1, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 2

```{python individual_images_c2, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 3

```{python individual_images_c3, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 4

```{python individual_images_c4, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)


## After equalization {.tabset}


### Channel 0

```{python eq_individual_images_c0, fig.height=12, fig.width=12}
active_lyr = eq_lyr
prefix = "input_after_equalization_channel_"

i = 0
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```
- Download: [`r py$save_path`](`r py$save_path`)

### Channel 1

```{python eq_individual_images_c1, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 2

```{python eq_individual_images_c2, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 3

```{python eq_individual_images_c3, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)

### Channel 4

```{python eq_individual_images_c4, fig.height=12, fig.width=12}
i += 1
save_path = f"{outdir}/{prefix}_{i}.png"
img.show(active_lyr, channel=i, cmap='gray')
plt.savefig(save_path, dpi=1000)
```

- Download: [`r py$save_path`](`r py$save_path`)


```{r session_info, collapse=FALSE}
sessionInfo()
```
