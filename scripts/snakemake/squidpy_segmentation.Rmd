---
title: "Squidpy Segmentation"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import dask.array as da
import matplotlib.pyplot as plt
import squidpy as sq
from matplotlib.colors import ListedColormap
from skimage.morphology import binary_erosion
import xarray as xr
import os
import ast
```

```{python configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Specify file paths to input and output files
outdir = params['outdir']
input_obj = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']
lyr_smth = f"{lyr}_smooth"

# Methods for segmentation and threholding
seg_method = params['seg_method']
thr_method = params['thr_method']
if thr_method == "None":
    thr_method = ast.literal_eval(thr_method)
```

# Loading input image

```{python loading_input}

# ------------------------------------------------------------------------------
# This chunk imports input image saved as zarr in the previous step
# ------------------------------------------------------------------------------

# Load the Zarr store into an ImageContainer
# Set lazy=True to enable Dask-backed lazy loading, which is memory-efficient for large images.
# You can also specify chunks for Dask if needed.
img = sq.im.ImageContainer.load(input_obj, lazy=True, chunks='auto')

print(f"The following file has been loaded: {input_obj}")
print(img)
```

# Segmentation {.tabset}

Image segmentation is performed using [Otsu thresholding](https://en.wikipedia.org/wiki/Otsu's_method) and 
[watershed](https://en.wikipedia.org/wiki/Watershed_(image_processing)) methods. In the Otsu method, 
the algorithm calculates the optimal brightness level that best separates regions of varying intensity. 
The watershed method is a region-based segmentation algorithm that divides an image into distinct adjacent
regions based on topographic analysis of pixel intensities.

```{python segmentation}

# ------------------------------------------------------------------------------
# This chunk carries out image segmentation using Otsu thresholding and watershed 
# segmentation. Segmentation is performed for each channel individually.
# ------------------------------------------------------------------------------

for ch in range(img[lyr].shape[3]):
    # Specify the name of layer for the new processed image
    new_layer = f"seg_channel_{ch}"
    # Run segmentation
    sq.im.segment(img=img,
                  layer=lyr_smth,
                  method=seg_method,
                  thresh=thr_method,
                  chunks='auto',
                  lazy=True,
                  layer_added=new_layer,
                  channel=ch)

# Prep a list consisting of channel corresponding to segmented images
seg_lyrs = [c for c in list(img) if "seg" in c]

# Create a list storing all dask arrays generated by squidpy segmentation
seg_arrays = [img[l] for l in seg_lyrs]

# Stack the arrays along the last axis
stacked_array = np.dstack(seg_arrays)
stacked_array = stacked_array.reshape(img[lyr].shape)

# Add the stacked array to the ImageContainer obj
lyr_seg = f"{lyr}_sqseg"
try:
    img[lyr_seg] = stacked_array
except:
    ValueError("Can't add the stacked array to ImageContainer. Wrong dimension!")

# Delete unnecessary layers
for l in seg_lyrs:
    del img[l]

print("ImageContainer updated:")
print(img)

```

```{r visualize_images, results='asis'}

# ------------------------------------------------------------------------------
# This chunk is used to prepare visualizing smoothened images
# ------------------------------------------------------------------------------

# Visualize input images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("## Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_seg, "', channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/sqseg_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0("sqseg_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/sqseg_channel_", i, ".png")
    link_output(paste0("sqseg_channel_", i, ".png"))
}

```

# Binarization {.tabset}

Binary masking data is generated by filtering pixels based on the segmentation pixels; any non-zero pixels 
are converted to 1.

```{python binarize_segmented_arrays}

# Prep a binary array storing masking information
binary_array = stacked_array > 0

# Add the binary array to the ImageConatiner obj
lyr_bn = f"{lyr}_sqbn"
try:
    img[lyr_bn] = binary_array
except:
    ValueError("Can't add the binary array to ImageContainer. Wrong dimension!")

    print("ImageContainer updated:")
print(img)
```

```{r vis_binary, results='asis'}

for (i in 1:py$img[[py$lyr]][['shape']][[4]]) { 
    # Convert into 0-indexing
    i <- i - 1
    cat('## Channel', i, '\n\n')
    t_deparsed_1 <- paste0("img.show(lyr_bn, channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/sqbn_channel_", i, ".png', dpi=1000)")
    t_deparsed <- c(t_deparsed_1, t_deparsed_2)
    subchunkify(name=paste0("sqbn_images_channel_", i), t_deparsed=t_deparsed)

    path <- paste0(py$outdir, "/sqbn_channel_", i, ".png")
    link_output(paste0("sqbn_channel_", i, ".png"))
    cat('\n\n')
}

```

# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```

```{r session_info, collapse=FALSE}
sessionInfo()
```
