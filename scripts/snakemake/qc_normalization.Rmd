---
title: "QC and normalization"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import matplotlib.pyplot as plt
import squidpy as sq
import dask.array as da
from skimage.exposure import equalize_adapthist
import xarray as xr
import os
```

```{python configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Specify file paths to input and output files
outdir = params['outdir']
input_image = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']

# Specify the size of chunks for height and width
chunksize = int(params['chunksize'])

# Specify the lower and upper percentiles for normalization
lower_percentile = int(params['lower_p'])
upper_percentile = int(params['upper_p'])
```

# Loading input images {.tabset}

We use `tif` image files converted from `vsi`. The following channels correspond to individual IFs.

- **Channel 0**: DAPI
- **Channel 1**: IBA1
- **Channel 2**: TDP43
- **Channel 3**: MAP2
- **Channel 4**: ALDH1L1

The following image object loaded:

```{python load_image}

# ------------------------------------------------------------------------------
# This chunk is used to load input image files
# ------------------------------------------------------------------------------

# Initialize ImageContainer
img = sq.im.ImageContainer(input_image, layer=lyr, lazy=True, chunks=chunksize)
```

Contrast enhancement is conducted using the `skimage.exposure.equalize_adapthist`
function with default parameter settings.

`ImageContainer` obj created using input image:

```{python print_status}
print(input_image)
print(img)
```

```{python input_intensity_histogram}

# ------------------------------------------------------------------------------
# This chunk sets up functions
# ------------------------------------------------------------------------------

# Create a function plotting intensity histogram
def intensity_histogram(layer=lyr, channel=0):
    # Retrieve a dask array
    arr = img[layer].data[:, :, 0, channel]

    # Define the bins for the histogram
    bins = np.linspace(0, arr.max().compute(), 50)

    # The `compute()` call triggers the parallel computation.
    hist, bins = da.histogram(arr, bins=bins)
    hist, bins = da.compute(hist, bins)

    # Plot the histogram
    plt.bar(bins[:-1], hist, width=np.diff(bins), edgecolor='black', alpha=0.7)
    plt.title(f'Channel {channel}')
    plt.xlabel('Intensity Value')
    plt.ylabel('Frequency')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.savefig(f"{outdir}/histogram_{layer}_channel_{channel}.png")
    plt.show()

# Create a function cleaning the `ImageContainer` obj with normalized layers
def clean_normalized_obj(img=img, in_keyword='clahe_channel', out_keyword='clahe'):

    # Prep a list consisting of channel corresponding to normalized images
    norm_lyrs = [c for c in list(img) if in_keyword in c]

    # Create a list storing all dask arrays generated by normalization
    norm_arrays = [img[l].data for l in norm_lyrs]

    # Stack the arrays along the last axis
    stacked_array = np.dstack(norm_arrays)
    stacked_array = stacked_array.reshape(img[lyr].shape)

    # Add the stacked array to the ImageContainer obj
    lyr_norm = f"{lyr}_{out_keyword}"
    try:
        img[lyr_norm] = stacked_array
    except:
        ValueError("Can't add the stacked array to ImageContainer. Wrong dimension!")

    # Delete unnecessary layers
    for l in norm_lyrs:
        del img[l]

    return img
```

```{r histogram_input, results='asis'}

# ------------------------------------------------------------------------------
# This chunk explores the intensity distribution of input images
# ------------------------------------------------------------------------------

# Visualize input intensities across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("\n\n## Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed <- paste0("intensity_histogram(layer='", py$lyr, "', channel=", i, ")")
    subchunkify(name=paste0("inputhist_", i), t_deparsed=t_deparsed, width=6, height=4)
    image_path <- paste0("histogram_", py$lyr, "_channel_", i, ".png")
    link_output(image_path)
}
```

# Normalizing intensities using Contrast Limited Adaptive Histogram Equalization (CLAHE) {.tabset}

[CLAHE](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization#Contrast_Limited_AHE)
is an algorithm for local contrast enhancement, that uses histograms computed over different
tile regions of the image. Local details can therefore be enhanced even in regions that are darker 
or lighter than most of the image.

```{python clahe_intensities}

# ------------------------------------------------------------------------------
# This chunk conducts CLAHE using the skimage.exposure.equalize_adapthist
# function
# ------------------------------------------------------------------------------

# Specify required parameters
clip_limit = 0.01
template = img[lyr].data[:, :, 0, 0]
kernel_size = chunksize * template.ndim

outkey = "clahe"
for ch in range(img[lyr].shape[3]):
    # Specify the name of layer for the new processed image
    new_layer = f"{outkey}_channel_{ch}"
    # Retrieve an array corresponding to the channel
    arr = img[lyr].data[:, :, 0, ch]
    # Run normalization
    arr_norm = da.map_overlap(equalize_adapthist,
                              arr,
                              depth=chunksize // 2,
                              boundary='reflect',
                              kernel_size=kernel_size,
                              clip_limit=clip_limit,
                              dtype=float)

    img.add_img(arr_norm, layer=new_layer)

# Update the `ImageContainer` with cleaned layers
img = clean_normalized_obj(img=img, in_keyword=f'{outkey}_channel', out_keyword=outkey)
# Add the stacked array to the ImageContainer obj
lyr_norm = f"{lyr}_{outkey}"

print("ImageContainer updated:")
print(img)
```

```{r vis_clahe, results='asis'}

# ------------------------------------------------------------------------------
# This chunk iteratively visualizes images transformed using CLAHE
# ------------------------------------------------------------------------------

cat('## Images {.tabset}\n\n')

# Visualize input images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_norm, "', channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/", py$outkey, "_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed)

    link_output(paste0(py$outkey, "_channel_", i, ".png"))
}

cat('## Histograms {.tabset}\n\n')

# Visualize input intensities across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("\n\n### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed <- paste0("intensity_histogram(layer='", py$lyr_norm, "', channel=", i, ")")
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed, width=6, height=4)
    image_path <- paste0("histogram_", py$lyr_norm, "_channel_", i, ".png")
    link_output(image_path)

}
```

# Normalizing intensities using log1p transformation {.tabset}

Additionally, intensities are normalized through log1p transformation.

```{python log_transformation}

# ------------------------------------------------------------------------------
# This chunk conducts normalization using log transformation
# ------------------------------------------------------------------------------

outkey = "lognorm"
for ch in range(img[lyr].shape[3]):
    # Specify the name of layer for the new processed image
    new_layer = f"{outkey}_channel_{ch}"
    # Retrieve an array corresponding to the channel
    arr = img[lyr].data[:, :, 0, ch]

    # Normalize the input array to the range [0, 1] if it's not already
    # This is a good practice for consistent scaling
    arr_normalized = arr / arr.max().compute()

    # Apply the log transformation
    # Dask's da.log1p handles this efficiently in a distributed manner
    arr_log_transformed = da.log1p(arr_normalized)

    # Now, rescale the transformed array back to the original data type's range
    # For example, to rescale to 0-255 for an 8-bit image
    max_val_original = 255
    min_val_original = 0

    # Compute the max value of the log-transformed array
    max_val_log = arr_log_transformed.max().compute()

    # Rescale to the original value range
    arr_norm = (arr_log_transformed * (max_val_original / max_val_log)).astype(np.uint8)

    # Add the array to the `ImageContainer` obj
    img.add_img(arr_norm, layer=new_layer)


# Update the `ImageContainer` with cleaned layers
img = clean_normalized_obj(img=img, in_keyword=f'{outkey}_channel', out_keyword=outkey)
# Add the stacked array to the ImageContainer obj
lyr_norm = f"{lyr}_{outkey}"

print("ImageContainer updated:")
print(img)
```

```{r lognorm_vis, results='asis'}

# ------------------------------------------------------------------------------
# This chunk iteratively visualizes images transformed using log-normalization
# ------------------------------------------------------------------------------

cat('## Images {.tabset}\n\n')

# Visualize input images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_norm, "', channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/", py$outkey, "_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/", py$outkey, "_channel_", i, ".png")
    link_output(paste0(py$outkey, "_channel_", i, ".png"))
}

cat('## Histograms {.tabset}\n\n')

# Visualize input intensities across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("\n\n### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed <- paste0("intensity_histogram(layer='", py$lyr_norm, "', channel=", i, ")")
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed, width=6, height=4)
    image_path <- paste0("histogram_", py$lyr_norm, "_channel_", i, ".png")
    link_output(image_path)

}
```

# Normalizing intensities using the percentiles of intensity values {.tabset}

This method normalizes intensities by re-scaling the values based on the upper 
and lower percentiles. Here, the following percentiles are used:

- upper percentile: `r py$upper_percentile`
- lower percentile: `r py$lower_percentile`


```{python percnorm}

# ------------------------------------------------------------------------------
# This chunk re-ranges intensity values based on the upper and lower percentiles
# ------------------------------------------------------------------------------

outkey = "percnorm"
for ch in range(img[lyr].shape[3]):
    # Specify the name of layer for the new processed image
    new_layer = f"{outkey}_channel_{ch}"
    # Retrieve an array corresponding to the channel
    arr = img[lyr].data[:, :, 0, ch]

    # Calculate min and max intensities
    arr_computed = arr.compute()
    stretch_min = np.percentile(arr_computed, lower_percentile)
    stretch_max = np.percentile(arr_computed, upper_percentile)

    # Normalize by applying the min and max percentages
    arr_clip = np.clip(arr_computed, stretch_min, stretch_max)
    arr_norm = (arr_clip - stretch_min) / (stretch_max - stretch_min)

    # Convert to a dask array
    arr_norm = da.from_array(arr_norm, chunks=chunksize)

    # Add the array to the `ImageContainer` obj
    img.add_img(arr_norm, layer=new_layer)


# Update the `ImageContainer` with cleaned layers
img = clean_normalized_obj(img=img, in_keyword=f'{outkey}_channel', out_keyword=outkey)
# Add the stacked array to the ImageContainer obj
lyr_norm = f"{lyr}_{outkey}"

print("ImageContainer updated:")
print(img)
```

```{r percnorm_vis, results='asis'}

# ------------------------------------------------------------------------------
# This chunk iteratively visualizes images transformed using percentile normalization
# ------------------------------------------------------------------------------

cat('## Images {.tabset}\n\n')

# Visualize input images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_norm, "', channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/", py$outkey, "_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/", py$outkey, "_channel_", i, ".png")
    link_output(paste0(py$outkey, "_channel_", i, ".png"))
}

cat('## Histograms {.tabset}\n\n')

# Visualize input intensities across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("\n\n### Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed <- paste0("intensity_histogram(layer='", py$lyr_norm, "', channel=", i, ")")
    subchunkify(name=paste0(py$outkey, "_", i), t_deparsed=t_deparsed, width=6, height=4)
    image_path <- paste0("histogram_", py$lyr_norm, "_channel_", i, ".png")
    link_output(image_path)

}
```


# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```

```{r session_info, collapse=FALSE}
sessionInfo()
```
