---
title: "QC and normalization"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import matplotlib.pyplot as plt
import squidpy as sq
import dask.array as da
from skimage.exposure import equalize_adapthist
import xarray as xr
import os
```

```{python configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Specify file paths to input and output files
outdir = params['outdir']
input_image = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']

# Specify the size of chunks for height and width
chunksize = int(params['chunksize'])

```

# Loading input images {.tabset}

We use `tif` image files converted from `vsi`. The following channels correspond to individual IFs.

- **Channel 0**: DAPI
- **Channel 1**: IBA1
- **Channel 2**: TDP43
- **Channel 3**: MAP2
- **Channel 4**: ALDH1L1

The following image object loaded:

```{python load_image}

# ------------------------------------------------------------------------------
# This chunk is used to load input image files
# ------------------------------------------------------------------------------

# Initialize ImageContainer
img = sq.im.ImageContainer(input_image, layer=lyr, lazy=True, chunks=chunksize)
```

Contrast enhancement is conducted using the `skimage.exposure.equalize_adapthist`
function with default parameter settings.

`ImageContainer` obj created using input image:

```{python print_status}
print(input_image)
print(img)
```

# Normalizing intensities {.tabset}

```{python norm_intensities}

# ------------------------------------------------------------------------------
# This chunk conducts normalization using the skimage.exposure.equalize_adapthist
# function
# ------------------------------------------------------------------------------

# Specify required parameters
clip_limit = 0.01
template = img[lyr].data[:, :, 0, 0]
kernel_size = [50] * template.ndim

for ch in range(img[lyr].shape[3]):
    # Specify the name of layer for the new processed image
    new_layer = f"norm_channel_{ch}"
    # Retrieve an array corresponding to the channel
    arr = img[lyr].data[:, :, :, ch]
    # Run normalization
    arr_norm = da.map_overlap(equalize_adapthist,
                              arr,
                              depth=1,
                              boundary='reflect',
                              kernel_size=kernel_size,
                              clip_limit=clip_limit,
                              dtype=float)

    img.add_img(arr_norm, layer=new_layer)

# Prep a list consisting of channel corresponding to normalized images
norm_lyrs = [c for c in list(img) if "norm_channel" in c]

# Create a list storing all dask arrays generated by normalization
norm_arrays = [img[l].data for l in norm_lyrs]

# Stack the arrays along the last axis
stacked_array = np.dstack(norm_arrays)
stacked_array = stacked_array.reshape(img[lyr].shape)

# Add the stacked array to the ImageContainer obj
lyr_norm = f"{lyr}_norm"
try:
    img[lyr_norm] = stacked_array
except:
    ValueError("Can't add the stacked array to ImageContainer. Wrong dimension!")

# Delete unnecessary layers
for l in norm_lyrs:
    del img[l]

print("ImageContainer updated:")
print(img)
```

Contrast enhancement is conducted using the `skimage.exposure.equalize_adapthist`
function with default parameter settings.

```{r vis_input, results='asis'}

# ------------------------------------------------------------------------------
# This chunk iteratively visualizes images before and after smoothing
# ------------------------------------------------------------------------------

# Visualize input images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("## Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_norm, "', channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/norm_channel_", i,  ".png', dpi=1000)")
    t_deparsed <- c(t_deparsed_1, t_deparsed_2)
    subchunkify(name=paste0("norm_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/norm_channel_", i, ".png")
    link_output(paste0("norm_channel_", i, ".png"))
}
```


# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```

```{r session_info, collapse=FALSE}
sessionInfo()
```
