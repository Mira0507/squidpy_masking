---
title: "Watershed segmentation"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import dask.array as da
import matplotlib.pyplot as plt
import squidpy as sq
import xarray as xr
import os
```

```{python config}
# ------------------------------------------------------------------------------
# This chunk configures user-specified variables
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Paths to input and output obj
input_obj = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']

# Specify the size of chunks for height and width
chunksize = int(params['chunksize'])

# Path to output directory
outdir = params['outdir']

# Specify the name of input and output layers
lyr_processed = f"{lyr}_removal"
lyr_seg = f"{lyr}_ntseg"
```

# Loading input image

```{python loading_input}

# ------------------------------------------------------------------------------
# This chunk imports input image saved as zarr in the previous step
# ------------------------------------------------------------------------------

# Load the Zarr store into an ImageContainer
# Set lazy=True to enable Dask-backed lazy loading, which is memory-efficient for large images.
# You can also specify chunks for Dask if needed.
img = sq.im.ImageContainer.load(input_obj, lazy=True, chunks=chunksize)

print(f"The following file has been loaded: {input_obj}")
print(img)
```

# Watershed segmentation {.tabset}

The watershed is a classical algorithm used for segmentation, that is, 
for separating different foreground objects in an image. The watershed 
algorithm treats pixels values as a local topography (elevation). The 
algorithm floods basins from the markers until basins attributed to 
different markers meet on watershed lines. In many cases, markers are 
chosen as local minima of the image, from which basins are flooded.

```{python watershed_segmentation}

# ------------------------------------------------------------------------------
# This chunk conducts watershed segmentation on masked images using 
# native image-processing functions from the scikit-image and dask
# packages
# ------------------------------------------------------------------------------

# Run watershed segmentation using the wrapper function from Squidpy
for ch in range(img[lyr].shape[3]):
    new_layer = f"{lyr_seg}_channel_{ch}"
    sq.im.segment(img=img, 
                  layer=lyr_processed, 
                  method="watershed",
                  channel=ch,
                  chunks=chunksize, 
                  lazy=True, 
                  layer_added=new_layer)


# Prep a list consisting of channel corresponding to segmented images
seg_lyrs = [c for c in list(img) if "channel" in c]

# Create a list storing all dask arrays generated by watershed segmentation
seg_arrays = [img[l] for l in seg_lyrs]

# Stack the arrays along the last axis
stacked_array = np.dstack(seg_arrays)
stacked_array = stacked_array.reshape(img[lyr].shape)

# Add the stacked array to the ImageContainer obj
try:
    img[lyr_seg] = stacked_array
except:
    ValueError("Can't add the stacked array to ImageContainer. Wrong dimension!")

# Delete unnecessary layers
for l in seg_lyrs:
    del img[l]

print("ImageContainer updated:")
print(img)
```

```{r visualize_watershed, results='asis'}

# ------------------------------------------------------------------------------
# This chunk is used to prepare visualizing processed images
# ------------------------------------------------------------------------------

# Visualize processed images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("## Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_seg, "', channel=", i, ", cmap='gray')")
     t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/ntseg_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0("ntseg_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/ntseg_channel_", i, ".png")
    link_output(paste0("ntseg_channel_", i, ".png"))
}

```


# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```


```{r session_info, collapse=FALSE}
sessionInfo()
```
