---
title: "Watershed segmentation"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)


```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv(params[['conda_env']])
source('config/helpers.R')
```

```{python ppackages}
import numpy as np
import dask.array as da
import matplotlib.pyplot as plt
from scipy import ndimage as ndi
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
import squidpy as sq
import xarray as xr
import os
```

```{python config}
# ------------------------------------------------------------------------------
# This chunk configures user-specified variables
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Convert `params` from R to Python
params = r.params

# Paths to input and output obj
input_obj = params['input_obj']
output_obj = params['output_obj']

# Specify the name of input image layer to be processed
lyr = params['lyr']

# Specify the size of chunks for height and width
chunksize = int(params['chunksize'])

# Path to output directory
outdir = params['outdir']

# Specify the name of input and output layers
lyr_processed = f"{lyr}_removal"
lyr_seg = f"{lyr}_ntseg"

# Specify scaling factor for array downsampling
down_factor = int(params['downfactor'])
```

# Loading input image

```{python loading_input}

# ------------------------------------------------------------------------------
# This chunk imports input image saved as zarr in the previous step
# ------------------------------------------------------------------------------

# Load the Zarr store into an ImageContainer
# Set lazy=True to enable Dask-backed lazy loading, which is memory-efficient for large images.
# You can also specify chunks for Dask if needed.
img = sq.im.ImageContainer.load(input_obj, lazy=True, chunks=chunksize)

print(f"The following file has been loaded: {input_obj}")
print(img)
```

# Watershed segmentation {.tabset}

The watershed is a classical algorithm used for segmentation, that is, 
for separating different foreground objects in an image. The watershed 
algorithm treats pixels values as a local topography (elevation). The 
algorithm floods basins from the markers until basins attributed to 
different markers meet on watershed lines. In many cases, markers are 
chosen as local minima of the image, from which basins are flooded.

```{python watershed_segmentation}

# ------------------------------------------------------------------------------
# This chunk conducts watershed segmentation on masked images using 
# native image-processing functions from the scikit-image and dask
# packages
# ------------------------------------------------------------------------------

# Run watershed segmentation 
for ch in range(img[lyr].shape[3]):
    # Specify the name of new layer
    new_layer = f"{lyr_seg}_channel_{ch}"
    # Extract the dask array for given channel
    d_arr = img[lyr_processed].data[:, :, 0, ch]
    # Convert the dask array into an xarray without chunking
    x_arr = xr.DataArray(d_arr)
    x_arr = x_arr.chunk(-1)
    # Calculate the Euclidean distance of each foreground object 
    # from the background
    distance = ndi.distance_transform_edt(x_arr)
    # Find local maxima
    # NOTE: Optionally, we downsample and rescale before and after peak finding  
    distance_small = distance[::down_factor, ::down_factor]
    coords_small = peak_local_max(distance_small,
        min_distance=5,
        labels=x_arr[::down_factor, ::down_factor])
    coords = coords_small * down_factor
    # Select only those coordinates that are inside the image.
    coords = coords[(coords[:,0] < x_arr.shape[0]) & (coords[:,1] < x_arr.shape[1])]
    # Mask
    mask = np.zeros(distance.shape, dtype=bool)
    mask[tuple(coords.T)] = True
    markers, _ = ndi.label(mask)
    # Run watershed segmentation and convert the output into an xarray
    labels = xr.DataArray(watershed(-distance, markers, mask=x_arr))
    # Convert the xarray into a dask array with proper chunksize
    labels_chunked = labels.chunk(chunks=chunksize)
    # Add the processed array to the `ImageContainer` obj
    img.add_img(labels_chunked, layer=new_layer)


# Prep a list consisting of channel corresponding to segmented images
seg_lyrs = [c for c in list(img) if "channel" in c]

# Create a list storing all dask arrays generated by watershed segmentation
seg_arrays = [img[l] for l in seg_lyrs]

# Stack the arrays along the last axis
stacked_array = np.dstack(seg_arrays)
stacked_array = stacked_array.reshape(img[lyr].shape)

# Add the stacked array to the ImageContainer obj
try:
    img[lyr_seg] = stacked_array
except:
    ValueError("Can't add the stacked array to ImageContainer. Wrong dimension!")

# Delete unnecessary layers
for l in seg_lyrs:
    del img[l]

print("ImageContainer updated:")
print(img)

```

```{r visualize_watershed, results='asis'}

# ------------------------------------------------------------------------------
# This chunk is used to prepare visualizing processed images
# ------------------------------------------------------------------------------

# Visualize processed images across the channels
for (i in 1:py$img[[py$lyr]][['shape']][[4]]) {
    # Convert into 0-indexing
    i <- i - 1
    cat("## Channel", i, "{.tabset}\n\n")
    # Command to show image
    t_deparsed_1 <- paste0("img.show('", py$lyr_seg, "', channel=", i, ", cmap='gray')")
     t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/ntseg_channel_", i,  ".png', dpi=1000)")
    t_deparsed_3 <- "plt.close()"
    t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3)
    subchunkify(name=paste0("ntseg_", i), t_deparsed=t_deparsed)

    save_path <- paste0(py$outdir, "/ntseg_channel_", i, ".png")
    link_output(paste0("ntseg_channel_", i, ".png"))
}

```


# Saving the `ImageContainer` object

Output images are saved as the following object:

```{python save_zarr}
img.save(output_obj)
print(output_obj)
```


```{r session_info, collapse=FALSE}
sessionInfo()
```
