---
title: "Segmentation using squidpy"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)

```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv('../../env')
```

```{python ppackages}
import numpy as np
import matplotlib.pyplot as plt
import squidpy as sq
from tifffile import imread
from matplotlib.colors import ListedColormap
import napari
import os
```

```{python configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Specify file paths to input and output files
outdir = "segmentation_perm_1000"
input_image = f"image_conversion_perm/converted_168.ome.tif"
output_obj = f"{outdir}/icontainer_168_1000.zarr"

# Create the output directory 
os.makedirs(outdir, exist_ok=True)

# Specify argument setting for printing images
channel_config = {
    'Merged' : {'ch' : None, 'cm' : None},
    'Channel 0' : {'ch' : 0, 'cm' : 'gray'},
    'Channel 1' : {'ch' : 1, 'cm' : 'gray'},
    'Channel 2' : {'ch' : 2, 'cm' : 'gray'},
    'Channel 3' : {'ch' : 3, 'cm' : 'gray'},
    'Channel 4' : {'ch' : 4, 'cm' : 'gray'}
}

# Specify the name of input image layer to be processed
lyr = 'image'

# Specify signal values to be tested for Gaussian smoothing
# Sigma represents the variance for normal distribution
gaussian_sigma = 1

# Specify whether input images will be cropped
crop_images = True

# Specify coordinates to crop images
crop_coord = {'height' : 0.5, 'width' : 0.5, 'size' : 1000, 'scale' : 1}

# Specify the segmentation method
seg_method = "watershed"

# Specify the thresholding method. If `None`, the Otsu method is used.
thr_method = None

# Specify pseudocolors across the channels
col_dic = {
    'dapi': 'dodgerblue',
    'iba': 'rosybrown',
    'tdp': 'orange',
    'map': 'cyan',
    'aldh': 'darkkhaki'}


# Specify merges
merge_list = ['dapi_tdp', 'iba_map_aldh', 'tdp_map']
```

# Loading input images {.tabset}

We use `tif` image files converted from `vsi`. Refer to the [image_conversion.html](image_conversion.html) 
for detailed processes on converting image formats.

The following image object loaded:

```{python load_image}

# ------------------------------------------------------------------------------
# This chunk is used to load input image files
# ------------------------------------------------------------------------------

# Read image as numpy array
img_array = imread(input_image)

# Initialize ImageContainer
img = sq.im.ImageContainer(img_array, layer=lyr)

print("ImageContainer obj created using input image:", img)

# Crop input images if specified
if crop_images:
    print("Image cropped. Refer to the following dimension:", crop_coord)
    img = img.crop_corner(x=crop_coord['width'],
                          y=crop_coord['height'],
                          size=crop_coord['size'],
                          scale=crop_coord['scale'])
    print("ImageContainer obj updated:", img)
```

## Channel 0

```{python individual_images_c0, fig.height=12, fig.width=12}
i = 0
img.show(lyr, channel=i, cmap='gray')
plt.savefig(f"{outdir}/input_channel_{i}.png", dpi=1000)
```

## Channel 1

```{python individual_images_c1, fig.height=12, fig.width=12}
i += 1
img.show(lyr, channel=i, cmap='gray')
plt.savefig(f"{outdir}/input_channel_{i}.png", dpi=1000)
```

## Channel 2

```{python individual_images_c2, fig.height=12, fig.width=12}
i += 1
img.show(lyr, channel=i, cmap='gray')
plt.savefig(f"{outdir}/input_channel_{i}.png", dpi=1000)
```

## Channel 3

```{python individual_images_c3, fig.height=12, fig.width=12}
i += 1
img.show(lyr, channel=i, cmap='gray')
plt.savefig(f"{outdir}/input_channel_{i}.png", dpi=1000)
```

## Channel 4

```{python individual_images_c4, fig.height=12, fig.width=12}
i += 1
img.show(lyr, channel=i, cmap='gray')
plt.savefig(f"{outdir}/input_channel_{i}.png", dpi=1000)
```

# Smoothing {.tabset}

Smoothing is required to reduce noises before image masking. The current workflow uses 
[Gaussian smoothing](https://en.wikipedia.org/wiki/Gaussian_blur) by calling 
the `squidpy.im.process(..., method="smooth")`, which implements the `skimage.filters.gaussian` function 
in the `scikit-image` package in python.

```{python smoothing}

# --------------------------------------------------------------------------------
# This chunk runs Gaussian smoothing
# --------------------------------------------------------------------------------

# Run smoothing
sq.im.process(img, layer=lyr, method="smooth", sigma=gaussian_sigma)
```
`ImageContainer` updated:

```{r smoothened_obj}
py$img
```

Images are compared between the before (left) and the after (right) smoothing across the stainings.


```{python function_processed}

# ------------------------------------------------------------------------------
# This chunk is used to prepare visualizing smoothened images
# ------------------------------------------------------------------------------

# Specify the name of layer containing Gaussian smoothing
lyr_smth = f"{lyr}_smooth"

# Create a function that prints images before and after Gaussian smoothing
def image_original_processed(l_one, l_two, image, channels, process):
    # Design subplots
    fig, axes = plt.subplots(nrows=1, ncols=2)
    image.show(layer=l_one, channel=channels[0], cmap='gray', ax=axes[0])
    _ = axes[0].set_title(f"Original before {process}")
    image.show(layer=l_two, channel=channels[1], cmap='gray', ax=axes[1])
    _ = axes[1].set_title(f"Original after {process}")
    # Save
    ch = "_".join([str(x) for x in channels])
    plt.savefig(f"{outdir}/masked_channel_{ch}.png", dpi=1000)

```

## Channel 0

```{python smth_images_c0, fig.width=12, fig.height=12}
i = 0
image_original_processed(l_one=lyr,
                         l_two=lyr_smth,
                         image=img,
                         channels=[i, i],
                         process="smoothing")
```

## Channel 1

```{python smth_images_c1, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=lyr_smth,
                         image=img,
                         channels=[i, i],
                         process="smoothing")
```

## Channel 2

```{python smth_images_c2, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=lyr_smth,
                         image=img,
                         channels=[i, i],
                         process="smoothing")
```

## Channel 3

```{python smth_images_c3, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=lyr_smth,
                         image=img,
                         channels=[i, i],
                         process="smoothing")
```

## Channel 4

```{python smth_images_c4, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=lyr_smth,
                         image=img,
                         channels=[i, i],
                         process="smoothing")
```

# Segmentation {.tabset}

Image segmentation is performed using [Otsu thresholding](https://en.wikipedia.org/wiki/Otsu's_method) and 
[watershed](https://en.wikipedia.org/wiki/Watershed_(image_processing)) methods. In the Otsu method, 
the algorithm calculates the optimal brightness level that best separates regions of varying intensity. 
The watershed method is a region-based segmentation algorithm that divides an image into distinct adjacent
regions based on topographic analysis of pixel intensities.

```{python segmentation}

# ------------------------------------------------------------------------------
# This chunk carries out image segmentation using Otsu thresholding and watershed 
# segmentation. Segmentation is performed for each channel individually.
# ------------------------------------------------------------------------------

for key, value in channel_config.items():
    # For any valid channel
    if value['ch'] != None:
        # Specify the channel to be processed
        ch = value['ch']
        # Specify the name of layer for the new processed image
        new_layer = f"seg_channel_{ch}"
        # Run segmentation
        sq.im.segment(img=img,
                      layer=lyr_smth,
                      method=seg_method,
                      thresh=thr_method,
                      layer_added=new_layer,
                      channel=ch)

# Prep a list consisting of channel corresponding to segmented images
seg_lyrs = [c for c in list(img) if "seg" in c]
```

`ImageContainer` updated:

```{r seg_obj}
py$img
```

Images are compared between the before (left) and the after (right) segmentation across the stainings.

## Channel 0

```{python seg_images_c0, fig.width=12, fig.height=12}
i = 0
image_original_processed(l_one=lyr,
                         l_two=seg_lyrs[i],
                         image=img,
                         channels=[i, None],
                         process="segmentation")
```

## Channel 1

```{python seg_images_c1, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=seg_lyrs[i],
                         image=img,
                         channels=[i, None],
                         process="segmentation")
```

## Channel 2

```{python seg_images_c2, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=seg_lyrs[i],
                         image=img,
                         channels=[i, None],
                         process="segmentation")
```

## Channel 3

```{python seg_images_c3, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=seg_lyrs[i],
                         image=img,
                         channels=[i, None],
                         process="segmentation")
```

## Channel 4

```{python seg_images_c4, fig.width=12, fig.height=12}
i += 1
image_original_processed(l_one=lyr,
                         l_two=seg_lyrs[i],
                         image=img,
                         channels=[i, None],
                         process="segmentation")
```

# Merging masked images {.tabset}

We are merging binarized signals across the antibodies of interest. Refer to the following pseudo-colors:

```{r print_pseudocolors}
print(py$col_dic)
```


```{python prep_merge}

# ------------------------------------------------------------------------------
# this chunk is used to prepare arrays and function
# ------------------------------------------------------------------------------

# Extract all binarized array data
binary_arr = [np.squeeze(img[l].values) for l in seg_lyrs]

def display_merge(merge_name):

    # Extract antibody and channel
    ch_list = list(merge_name.split("_"))
    ch_dic = {ab: i for i, ab in enumerate(col_dic.keys()) if ab in ch_list}

    # Stack binary images
    for ab, i in ch_dic.items():
        plt.imshow(binary_arr[i],
                   cmap=ListedColormap([(1, 1, 1, 0), col_dic[ab]]),
                   alpha=0.5)
    plt.xticks([])
    plt.yticks([])
    plt.savefig(f"{outdir}/{merge_name}.png", dpi=1000)
    plt.show()

```

## DAPI + TDP43

```{python merge0, fig.width=12, fig.height=12}
i = 0
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[1]`.png](`r py$outdir`/`r py$merge_list[1]`.png)

## IBA1 + MAP2 + ALDH1L1

```{python merge1, fig.width=12, fig.height=12}
i += 1
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[2]`.png](`r py$outdir`/`r py$merge_list[2]`.png)

## TDP43 + MAP2

```{python merge2, fig.width=12, fig.height=12}
i += 1
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[3]`.png](`r py$outdir`/`r py$merge_list[3]`.png)

```{python save_zarr}
img.save(output_obj)
```

```{python load_napari, eval=FALSE}

# ------------------------------------------------------------------------------
# This chunk is used to explore images using the Napari image viewer. 
# Manually reorder the dimension if necessary.
# ------------------------------------------------------------------------------

# Initialize napari viewer
viewer = napari.Viewer()

for l in seg_lyrs:
    # Extract ndarray
    arr = img.data[l].values
    # Reorder dimensions
    # NOTE: Ensure to have a compatible dimension with Napari (z, channel, y, z)
    d_y, d_x, d_z, d_ch = arr.shape
    arr_reshaped = arr.reshape(d_z, d_ch, d_y, d_x)
    # Add layers of interest to napari viewer
    viewer.add_image(arr_reshaped, name=l)

# Explore loaded images
napari.run()
```

```{r session_info, collapse=FALSE}
sessionInfo()
```
