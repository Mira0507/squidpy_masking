---
title: "Segmentation using squidpy"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        # toc: true
        # toc_float: true
        # toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to demonstrate image segmentation for Visium analysis 
using the [squidpy (Palla, Spitzer et al., 2022)](https://doi.org/10.1038/s41592-021-01358-2) package.
Refer to the following resources for technical details:

- [Squidpy documentation](https://squidpy.readthedocs.io/en/stable/index.html)
- [Tutorial: Analyze Visium fluorescence data](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_visium_fluo.html)
- [Squidpy GitHub](https://github.com/scverse/squidpy)

```{r rpackages}
library(reticulate)
library(tidyverse)
use_condaenv('../../env')
source('../snakemake/config/helpers.R')
```

```{python ppackages}
import numpy as np
import matplotlib.pyplot as plt
import squidpy as sq
from tifffile import imread
from matplotlib.colors import ListedColormap
import dask.array as da
import xarray as xr
import os
```

```{python configs}

# ------------------------------------------------------------------------------
# This chunk is used to specify variables for paths to input files/directories
# and parameter settings
# ------------------------------------------------------------------------------

# reticulate::repl_python()

# Specify file paths to input and output files
outdir = "segmentation_perm_500"
input_image = f"image_conversion_perm/converted_168.ome.tif"
output_obj = f"{outdir}/icontainer_168_500.zarr"

# Create the output directory 
os.makedirs(outdir, exist_ok=True)

# Specify the name of input image layer to be processed
lyr = 'image'

# Specify signal values to be tested for Gaussian smoothing
# Sigma represents the variance for normal distribution
gaussian_sigma = 1

# Specify whether input images will be cropped
crop_images = True

# Specify coordinates to crop images
crop_coord = {'height' : 0.5, 'width' : 0.5, 'size' : 500, 'scale' : 1}

# Specify the segmentation method
seg_method = "watershed"

# Specify the thresholding method. If `None`, the Otsu method is used.
thr_method = None

# Specify pseudocolors across the channels
col_dic = {
    'dapi': 'dodgerblue',
    'iba': 'rosybrown',
    'tdp': 'orange',
    'map': 'cyan',
    'aldh': 'darkkhaki'}

# Specify merges
merge_list = ['dapi_tdp', 'iba_map_aldh', 'tdp_map']


```

# Loading input images {.tabset}

We use `tif` image files converted from `vsi`. Refer to the [image_conversion.html](image_conversion.html) 
for detailed processes on converting image formats.

The following image object loaded:

```{python load_image}

# ------------------------------------------------------------------------------
# This chunk is used to load input image files
# ------------------------------------------------------------------------------

# Read image as numpy array
img_array = imread(input_image)

# Initialize ImageContainer
img = sq.im.ImageContainer(img_array, layer=lyr)

print("ImageContainer obj created using input image:", img)

# Crop input images if specified
if crop_images:
    print("Image cropped. Refer to the following dimension:", crop_coord)
    img = img.crop_corner(x=crop_coord['width'],
                          y=crop_coord['height'],
                          size=crop_coord['size'],
                          scale=crop_coord['scale'])
    print("ImageContainer obj updated:", img)
```

```{r vis_input_images, results='asis'}

for (i in 1:py$img[[py$lyr]][['shape']][[4]]) { 
    # Convert into 0-indexing
    i <- i - 1
    cat('## Channel', i, '\n\n')
    t_deparsed_1 <- paste0("img.show(lyr, channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/input_channel_", i, ".png', dpi=1000)")
    t_deparsed <- c(t_deparsed_1, t_deparsed_2)
    subchunkify(name=paste0("input_images_channel_", i), t_deparsed=t_deparsed)

    path <- paste0(py$outdir, "/input_channel_", i, ".png")
    link_output(path)
    cat('\n\n')
}
```

# Smoothing {.tabset}

Smoothing is required to reduce noises before image masking. The current workflow uses 
[Gaussian smoothing](https://en.wikipedia.org/wiki/Gaussian_blur) by calling 
the `squidpy.im.process(..., method="smooth")`, which implements the `skimage.filters.gaussian` function 
in the `scikit-image` package in python.

```{python smoothing}

# --------------------------------------------------------------------------------
# This chunk runs Gaussian smoothing
# --------------------------------------------------------------------------------

# Run smoothing
sq.im.process(img, layer=lyr, method="smooth", sigma=gaussian_sigma)

# Specify the name of layer containing Gaussian smoothing
lyr_smth = f"{lyr}_smooth"

```
`ImageContainer` updated:

```{r smoothened_obj}
py$img
```

```{r vis_smooth, results='asis'}

for (i in 1:py$img[[py$lyr]][['shape']][[4]]) { 
    # Convert into 0-indexing
    i <- i - 1
    cat('## Channel', i, '\n\n')
    t_deparsed_1 <- paste0("img.show(lyr_smth, channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/smth_channel_", i, ".png', dpi=1000)")
    t_deparsed <- c(t_deparsed_1, t_deparsed_2)
    subchunkify(name=paste0("smth_images_channel_", i), t_deparsed=t_deparsed)

    path <- paste0(py$outdir, "/smth_channel_", i, ".png")
    link_output(path)
    cat('\n\n')
}
```

# Segmentation {.tabset}

Image segmentation is performed using [Otsu thresholding](https://en.wikipedia.org/wiki/Otsu's_method) and 
[watershed](https://en.wikipedia.org/wiki/Watershed_(image_processing)) methods. In the Otsu method, 
the algorithm calculates the optimal brightness level that best separates regions of varying intensity. 
The watershed method is a region-based segmentation algorithm that divides an image into distinct adjacent
regions based on topographic analysis of pixel intensities.

```{python segmentation}

# ------------------------------------------------------------------------------
# This chunk carries out image segmentation using Otsu thresholding and watershed 
# segmentation. Segmentation is performed for each channel individually.
# ------------------------------------------------------------------------------

# reticulate::repl_python()
for ch in range(img[lyr].shape[-1]):
    # Specify the name of layer for the new processed image
    new_layer = f"seg_channel_{ch}"
    # Run segmentation
    sq.im.segment(img=img,
                  layer=lyr_smth,
                  method=seg_method,
                  thresh=thr_method,
                  layer_added=new_layer,
                  channel=ch)

# Prep a list consisting of channel corresponding to segmented images
seg_lyrs = [c for c in list(img) if "seg" in c]
seg_arr = [np.squeeze(img[l].values) for l in seg_lyrs]

# Stack the arrays along the last axis
stacked_arr = np.dstack(seg_arr)
stacked_arr = stacked_arr.reshape(img[lyr].shape)

# Add the stacked array to the ImageContainer obj
lyr_seg = f"{lyr}_sqseg"
try:
    img['image_sqseg'] = stacked_arr
except:
    ValueError("Wrong dimension!")

# Delete unnecessary layers
for l in seg_lyrs: 
    del img[l]

print("ImageContainer updated:")
print(img)

```

```{r vis_seg, results='asis'}

for (i in 1:py$img[[py$lyr]][['shape']][[4]]) { 
    # Convert into 0-indexing
    i <- i - 1
    cat('## Channel', i, '\n\n')
    t_deparsed_1 <- paste0("img.show(lyr_seg, channel=", i, ", cmap='gray')")
    t_deparsed_2 <- paste0("plt.savefig('", py$outdir, "/sqseg_channel_", i, ".png', dpi=1000)")
    t_deparsed <- c(t_deparsed_1, t_deparsed_2)
    subchunkify(name=paste0("sqseg_images_channel_", i), t_deparsed=t_deparsed)

    path <- paste0(py$outdir, "/sqseg_channel_", i, ".png")
    link_output(path)
    cat('\n\n')
}
```

# Comparison of intensities after each process

```{python intensity_dic}

# ------------------------------------------------------------------------------
# This chunk computes row-wise intensities across the layers and channels
# ------------------------------------------------------------------------------

# Prep a dictionary storing summed row-wise intensities for each layer
all_lyrs = list(img)
idic = {}

for l in all_lyrs:
    input_arrays = [np.squeeze(img[l][:, :, :, i]) for i in range(img[l].shape[-1])]
    summed_rows = [a.sum(axis=1) for a in input_arrays]
    idic[l] = summed_rows


```

```{r vis_intensities, results='asis'}

for (i in seq_along(py$img[[py$lyr]][['shape']][[4]])) { 
    i <- i - 1
    cat('\n\n## Channel', i, '{.tabset}\n\n')
    for (l in py$all_lyrs) {
        cat('\n\n### Layer:', l, '\n\n')
        t_deparsed_1 <- paste0("plt.plot(idic[", l, "][", i, "], linestyle='-')")
        t_deparsed_2 <- "plt.xlabel('Row number')"
        t_deparsed_3 <- "plt.ylabel('Summed row-wise intensity')"
        t_deparsed_4 <- "plt.show()"
        t_deparsed <- c(t_deparsed_1, t_deparsed_2, t_deparsed_3, t_deparsed_4)
        subchunkify(name=paste0("input_intensities_", i),
                    t_deparsed=t_deparsed,
                    width=8,
                    height=6)
    }
}
```



# Merging masked images {.tabset}

We are merging binarized signals across the antibodies of interest. Refer to the following pseudo-colors:

```{r print_pseudocolors}
print(py$col_dic)
```


```{python prep_merge}

# ------------------------------------------------------------------------------
# this chunk is used to prepare arrays and function
# ------------------------------------------------------------------------------

# Extract all binarized array data
input_arr = [np.squeeze(img[lyr_seg][:, :, :, i]) for i in range(img[lyr_seg].shape[-1])]

def display_merge(merge_name):

    # Extract antibody and channel
    ch_list = list(merge_name.split("_"))
    ch_dic = {ab: i for i, ab in enumerate(col_dic.keys()) if ab in ch_list}

    # Stack binary images
    for ab, i in ch_dic.items():
        plt.imshow(input_arr[i],
                   cmap=ListedColormap([(1, 1, 1, 0), col_dic[ab]]),
                   alpha=0.5)
    plt.xticks([])
    plt.yticks([])
    plt.savefig(f"{outdir}/{merge_name}.png", dpi=1000)
    plt.show()

```

## DAPI + TDP43

```{python merge0, fig.width=12, fig.height=12}
i = 0
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[1]`.png](`r py$outdir`/`r py$merge_list[1]`.png)

## IBA1 + MAP2 + ALDH1L1

```{python merge1, fig.width=12, fig.height=12}
i += 1
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[2]`.png](`r py$outdir`/`r py$merge_list[2]`.png)

## TDP43 + MAP2

```{python merge2, fig.width=12, fig.height=12}
i += 1
display_merge(merge_list[i])
```

- Download: [`r py$outdir`/`r py$merge_list[3]`.png](`r py$outdir`/`r py$merge_list[3]`.png)

```{python save_zarr}
img.save(output_obj)
```

```{python load_napari, eval=FALSE}

# ------------------------------------------------------------------------------
# This chunk is used to explore images using the Napari image viewer. 
# Manually reorder the dimension if necessary.
# ------------------------------------------------------------------------------

# Initialize napari viewer
viewer = napari.Viewer()

for l in seg_lyrs:
    # Extract ndarray
    arr = img.data[l].values
    # Reorder dimensions
    # NOTE: Ensure to have a compatible dimension with Napari (z, channel, y, z)
    d_y, d_x, d_z, d_ch = arr.shape
    arr_reshaped = arr.reshape(d_z, d_ch, d_y, d_x)
    # Add layers of interest to napari viewer
    viewer.add_image(arr_reshaped, name=l)

# Explore loaded images
napari.run()
```

```{r session_info, collapse=FALSE}
sessionInfo()
```
